# -*- coding: utf-8 -*-
"""SP24_PAI_Mid-Term_Project - 021, 037.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hx43B6MGzMR7jAbWcukJ-eFSGZiulLS-

#Programming for Artificial Intellingence - Lab Mid Term Project

###Malaika Sattar FA22-BAI-021
###Sheeza Tanveer FA22-BAI-037

#**1. Dataset Selection**:

The dataset used in the project contains a dataframe named **myanimelist** containing information about various anime entries. The dataframe consists of 19311 rows (entries) and 12 columns containing attributes about each anime.

###**Data Columns:**

* **uid (int64)**: This column contains a unique identifier (integer) for each anime entry.
* **title (object)**: This column stores the title of the anime as a string.
* **synopsis (object)**: This column contains a textual description of the anime plot.
* **genre (object)**: This column specifies the genre(s) of the anime, stored as a comma-separated list of strings.
* **aired (object)**: This column contains information about when the anime aired, likely in string format.
* **episodes (float64)**: This column represents the number of episodes in the anime.
* **members (int64)**: This column indicates the number of users (members) on the platform who have listed this anime.
* **popularity (int64)**: This column holds a numerical value representing the popularity of the anime on the platform.
* **ranked (float64)**: This column likely contains the anime's ranking on the platform.
* **score (float64)**: This column represents the average user rating (score) for the anime.
* **img_url (object)**: This column contains the URL (string) of an image associated with the anime.
* **link (object)**: This column likely holds the URL (string) of a webpage containing more information about the anime.

#**2. Data Preprocessing**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

myanimelist = pd.read_csv("/content/myanimelist.csv", sep=',')
myanimelist

myanimelist.shape

"""##**Dataset Information before preprocessing:**"""

myanimelist.info()

"""##**Removing Null Values:**"""

myanimelist.isnull().sum()

myanimelist.dropna(how='any', inplace=True)
myanimelist.shape

myanimelist.isnull().sum()

"""##**Removing duplicate values:**"""

myanimelist.duplicated().sum()

myanimelist.drop_duplicates(inplace = True)
myanimelist.shape

myanimelist.duplicated().sum()

"""##**Dataset Information after preprocessing:**"""

myanimelist.info()

"""#**3. Exploratory Data Analysis (EDA)**:

##**Summary of Data:**
"""

myanimelist.describe()

"""##**Top Anime Community:**"""

top_anime = myanimelist.sort_values(by='members', ascending=False).head(20)
colors = ['skyblue', 'purple', 'lightgreen', 'gold', 'violet', 'lightcoral', 'blue', 'orange', 'lightpink', 'lightgrey']
plt.barh(top_anime['title'], top_anime['members'], color= colors)
plt.xlabel('Number of Members')
plt.title('Top Anime Community')
plt.tight_layout()
plt.show()

"""**Insights:**
* ***Death Note*** wears the crown for highest community members followed by *Shingeki no Kyojin* and *Sword Art Online*.

##**Overall Anime Ratings:**
"""

plt.hist(myanimelist['score'], bins=20, color="yellow", edgecolor='black')
plt.xlabel('Average Rating')
plt.ylabel('Frequency')
plt.title("Anime's Average Rating Distribution")
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Insights:**
* Most of the Anime ratings are spread between 5.5 - 7.0
* The distribution is left skewed

##**Top Anime based on Ratings:**
"""

top_rated_anime = myanimelist.sort_values(by='score', ascending=False).head(20)
colors = ['skyblue', 'purple', 'lightgreen', 'gold', 'violet', 'lightcoral', 'blue', 'orange', 'lightpink', 'lightgrey']
plt.barh(top_rated_anime['title'], top_rated_anime['score'], color=colors)
plt.xlabel('Average Rating')
plt.title('Top Anime based on Ratings')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""**Insights:**
* ***Fullmetal Alchemist: Brotherhood*** wears the crown for highest rating followed by *Steins;Gate* and *Hunter x Hunter(2021)*.

##**Anime Popularity Distribution:**
"""

plt.hist(myanimelist['popularity'], bins=20, color="green", edgecolor='black')
plt.xlabel('Average Popularity')
plt.ylabel('Frequency')
plt.title("Anime's Popularity Distribution")
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Insights:**
* Most of the Anime popularity is spread between 0 - 2000
* The distribution is unevenly spread and has multiple peaks.

##**Anime Start Years Distribution:**
"""

myanimelist['start_year'] = myanimelist['aired'].str.extract(r'(\d{4})').astype(float)
plt.hist(myanimelist['start_year'], bins=10, color='skyblue', edgecolor='black')
plt.xlabel('Start Year')
plt.ylabel('Frequency')
plt.title("Distribution of Anime Start Years")
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Insights:**
* Most of the Anime started airing in the 2010-2020 decade.
* The distribution is left skewed.

##**Anime Rank Distribution:**
"""

plt.hist(myanimelist['ranked'], bins=20, color="pink", edgecolor='black')
plt.xlabel('Rank')
plt.ylabel('Frequency')
plt.title("Anime's Rank Distribution")
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Insights:**
* The distribution is unevenly spread and has multiple peaks.

##**Number of episodes & Rating:**
"""

plt.scatter(myanimelist['episodes'], myanimelist['score'], c=myanimelist['score'], cmap='viridis')
plt.xlabel('Number of Episodes')
plt.ylabel('Rating')
plt.title('Rating vs. Number of Episodes')
plt.colorbar(label='Score')
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Insights:**
* Animes with episodes less than 250 are highly likely to have a higher ratiing i.e. above 7.

##**Anime Genre Distribution:**
"""

import re
genre_list = []
for genres in myanimelist['genre']:
    extracted_genres = re.findall(r'[\w]+', genres)
    genre_list.extend(extracted_genres)
genre_df = pd.DataFrame(genre_list, columns=['Genre'])
top_genres = genre_df['Genre'].value_counts().head(10)

colors = ['skyblue', 'purple', 'lightgreen', 'gold', 'violet', 'lightcoral', 'blue', 'orange', 'lightpink', 'lightgrey']
plt.barh(top_genres.index, top_genres.values, color=colors)
plt.xlabel('Number of Anime')
plt.ylabel('Genre')
plt.title('Top Anime Genres')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""**Insights:**
* ***Comedy*** is the most common genre among animes followed by ***Action*** and ***Fantasy***.

#**4. Model Implementatation**:

##**Linear Classifier:**
"""

# Import required libraries
import sklearn
import numpy as np
import matplotlib.pyplot as plt

# Load necessary functions and classes
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import SGDClassifier
from sklearn import metrics

# Extract 'score' and 'episodes' columns from myanimelist dataframe
X_data = myanimelist[['score', 'episodes']].values
y_data = myanimelist['title'].values

# Print shape of the extracted data
print("Original Dataset Shape:", X_data.shape, y_data.shape)

# Split the dataset into a training and a testing set (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=42)
print("\nTesting Dataset Shape:", X_train.shape, y_train.shape)

# Standardize the features
scaler = StandardScaler().fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

# Plot the training instances
plt.figure(figsize=(5, 3))
plt.subplots_adjust(bottom=0.05, top=0.9, left=0.05, right=0.95)
plt.title('Training instances', size='18')
plt.scatter(X_train[:, 0], X_train[:, 1], c=X_train[:, 0], cmap='viridis')
plt.xlabel('Score')
plt.ylabel('Episodes')
plt.show()

# Create the linear model SGDClassifier
linear_clf = SGDClassifier()

# Train the classifier using fit() function
linear_clf.fit(X_train, y_train)

# Evaluate the result
y_train_pred = linear_clf.predict(X_train)
print("\nThe Accuracy of our classifier is:", metrics.accuracy_score(y_train, y_train_pred) * 100)

# Calculate precision, recall, and F1 score
precision = metrics.precision_score(y_train, y_train_pred, average='weighted', zero_division=0)
recall = metrics.recall_score(y_train, y_train_pred, average='weighted', zero_division=0)
f1_score = metrics.f1_score(y_train, y_train_pred, average='weighted', zero_division=0)
print("\nPrecision:", precision)
print("Recall:", recall)
print("F1 Score:", f1_score)

# Prediction and cross-checking
random_index = np.random.randint(0, len(X_test))
test_instance = X_test[random_index].reshape(1, -1)

# Assuming user inputs 'score' and 'episodes'
user_score = float(input("Enter the score of the anime: "))
user_episodes = float(input("Enter the number of episodes of the anime: "))

# Standardize user input
user_input = scaler.transform([[user_score, user_episodes]])

# Predict anime based on user input
predicted_anime = linear_clf.predict(user_input)[0]

# Print predicted anime
print("Predicted Anime:", predicted_anime)

# Cross-check with actual score and episodes
actual_score = X_data[random_index][0]
actual_episodes = X_data[random_index][1]
print("Actual Score:", actual_score)
print("Actual Episodes:", actual_episodes)

"""##**Logistic Regression Classifier:**"""

# Import required libraries
import sklearn
import numpy as np
import matplotlib.pyplot as plt

# Load necessary functions and classes
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

# Extract 'score' and 'episodes' columns from myanimelist dataframe
X_data = myanimelist[['score', 'episodes']].values
y_data = myanimelist['title'].values

# Print shape of the extracted data
print("Original Dataset Shape:", X_data.shape, y_data.shape)

# Split the dataset into a training and a testing set (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=42)
print("\nTesting Dataset Shape:", X_train.shape, y_train.shape)

# Standardize the features
scaler = StandardScaler().fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

# Plot the training instances
plt.figure(figsize=(5, 3))
plt.subplots_adjust(bottom=0.05, top=0.9, left=0.05, right=0.95)
plt.title('Training instances', size='18')
plt.scatter(X_train[:, 0], X_train[:, 1], c=X_train[:, 0], cmap='viridis')
plt.xlabel('Score')
plt.ylabel('Episodes')
plt.show()

# Create the linear model LogisticRegression
logistic_reg = LogisticRegression(max_iter=100)

# Train the classifier using fit() function
logistic_reg.fit(X_train, y_train)

# Evaluate the result
y_train_pred = logistic_reg.predict(X_train)
print("\nThe Accuracy of our classifier is:", metrics.accuracy_score(y_train, y_train_pred) * 100)

# Calculate precision, recall, and F1 score
precision = metrics.precision_score(y_train, y_train_pred, average='weighted', zero_division=0)
recall = metrics.recall_score(y_train, y_train_pred, average='weighted', zero_division=0)
f1_score = metrics.f1_score(y_train, y_train_pred, average='weighted', zero_division=0)
print("\nPrecision:", precision)
print("Recall:", recall)
print("F1 Score:", f1_score)

# Prediction and cross-checking
random_index = np.random.randint(0, len(X_test))
test_instance = X_test[random_index].reshape(1, -1)

# Assuming user inputs 'score' and 'episodes'
user_score = float(input("Enter the score of the anime: "))
user_episodes = float(input("Enter the number of episodes of the anime: "))

# Standardize user input
user_input = scaler.transform([[user_score, user_episodes]])

# Predict anime based on user input
predicted_anime = logistic_reg.predict(user_input)[0]

# Print predicted anime
print("Predicted Anime:", predicted_anime)

# Cross-check with actual score and episodes
actual_score = X_data[random_index][0]
actual_episodes = X_data[random_index][1]
print("Actual Score:", actual_score)
print("Actual Episodes:", actual_episodes)

"""#**5. Conclusion and Recommendations**:

##**Comparison:**

Based on the performance of the two models, the Logistic Regression model appears to be better than the Linear Classifier model. Following is the breakdown of the performance metrics:

* **Accuracy:** Logistic Regression has a significantly higher accuracy (0.2002) compared to the Linear Classifier (0.0091). This indicates that the Logistic Regression model is better at correctly predicting the category of an anime.

* **Precision and Recall:** While both models have very low precision and recall values, Logistic Regression has slightly higher values in both metrics. Precision refers to the proportion of correctly predicted positives among all predicted positives, while recall refers to the proportion of correctly predicted positives among all actual positives.

* **F1 Score:** Logistic Regression also has a higher F1 score (0.00043) compared to the Linear Classifier (2.6e-08). The F1 score is a harmonic mean of precision and recall, so a higher F1 score indicates a better balance between these two metrics.

##**Conclusion:**

* The logistic regression model outperforms the linear classifier in terms of accuracy, precision, recall, and F1 score. However, the performance of both models is quite poor.
* The logistic regression model correctly predicted the anime title based on the provided score and number of episodes, but with a low accuracy.

##**Recommendations:**

It is important to note that both the models have low accuracy mainly because the dataset is too simple and the features don't really relate to each other in a clear way. This makes it hard for the models to figure out how to predict accurately. Also, the models used might not be the best choice for this kind of dataset. They assume that the relationship between features and the thing we're trying to predict is simple and straight, but in this case, it's not. So even if we try different tricks to make the models better, like changing settings or adding more information, it's still tough for them to do well because they're not a good match for this type of data. We might need to try different models or find better ways to pick out which information is important for making predictions. Here are some recommendations as to how this data can be used to train better models:
* **Model Selection:** Experiment with other classification algorithms beyond linear classifier and logistic regression, such as decision trees, random forests, gradient boosting, or neural networks.
* **Hyperparameter Tuning:** Fine-tune the hyperparameters of the chosen models to optimize performance.
* **Ensemble Methods:** Combine multiple models to leverage the strengths of each and potentially improve overall performance.
* **Cross-Validation:** Utilize techniques like k-fold cross-validation to better estimate the model's performance and reduce overfitting.
"""